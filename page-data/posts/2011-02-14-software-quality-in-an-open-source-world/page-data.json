{"componentChunkName":"component---src-templates-blog-post-tsx","path":"/posts/2011-02-14-software-quality-in-an-open-source-world","webpackCompilationHash":"c8ed51f8e74f03200d92","result":{"data":{"site":{"siteMetadata":{"title":"Excursion in Distraction","author":"@dsvensson"}},"markdownRemark":{"html":"<p>As it’s always been a bit too far behind the scenes I wanted to take some time to describe what measurements has been taken to increase the quality of XMMS2, and what the future has in stock.</p>\n<p>Today we have a basic unit test framework built on top of <a href=\"https://web.archive.org/web/20110228135855/http://cunit.sourceforge.net/\" title=\"libcunit, unit testing library\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">libcunit</a>. To reduce boiler plate code in the actual test suites a number of macros have been defined. Here is an example of the basic structure of a simple test suite:</p>\n<div class=\"gatsby-highlight\" data-language=\"c\"><pre class=\"language-c\"><code class=\"language-c\">SETUP <span class=\"token punctuation\">(</span>mytestsuite<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n  <span class=\"token comment\">/* setup what ever is needed\n   * for each test case to run\n   */</span>\n<span class=\"token punctuation\">}</span>\n\nCLEANUP <span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n  <span class=\"token comment\">/* clean up such that the state\n   * is restored to the state before\n   * SETUP (mytestsuite) was run.\n   */</span>\n<span class=\"token punctuation\">}</span>\n\nCASE <span class=\"token punctuation\">(</span>mytestcase1<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n  <span class=\"token comment\">/* the actual test */</span>\n<span class=\"token punctuation\">}</span>\n\nCASE <span class=\"token punctuation\">(</span>mytestcase2<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n  <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<p>To guarantee correctness <code class=\"language-text\">SETUP</code> will be executed before each <code class=\"language-text\">CASE</code> is run, and <code class=\"language-text\">CLEANUP</code> will be executed after each <code class=\"language-text\">CASE</code> has finished. Additionally the whole <code class=\"language-text\">SETUP</code>, <code class=\"language-text\">CASE</code>, <code class=\"language-text\">CLEANUP</code> is wrapped by the following checks both before and after:</p>\n<div class=\"gatsby-highlight\" data-language=\"none\"><pre class=\"language-none\"><code class=\"language-none\">VALGRIND_DO_LEAK_CHECK;\nVALGRIND_COUNT_LEAKS(leak, d, r, s);</code></pre></div>\n<p>This imposes no runtime dependency but injects markers such that if the test is executed under <a href=\"https://web.archive.org/web/20110622085844/http://valgrind.org:80/docs/manual/mc-manual.html#mc-manual.clientreqs\" title=\"Valgrind, the instrumentation framework for building dynamic analysis tools.\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><em>Valgrind</em></a>, each test case will be inspected for memory leaks independently, which causes that test case to fail if a leak is found.</p>\n<p>That covers writing test cases and validating their resource management, next up is getting a clear view of what has been tested and this is where coverage reports come into play. To get coverage reporting, via <a href=\"https://web.archive.org/web/20100128043657/http://gcc.gnu.org:80/onlinedocs/gcc/Gcov.html\" title=\"gcov - coverage testing tool\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><em>gcov</em></a>, the <code class=\"language-text\">--coverage</code> flag is appended to both <code class=\"language-text\">CFLAGS</code> and <code class=\"language-text\">LINKFLAGS</code> in the build system. When running the tests a heap of <code class=\"language-text\">.gcda</code> and <code class=\"language-text\">.gcno</code> files will be emited which among other things contains the metadata about what lines were executed. To produce something that’s easy to inspect <a href=\"https://web.archive.org/web/20110318154531/http://ltp.sourceforge.net:80/coverage/lcov.php\" title=\"LCOV - the LTP GCOV extension\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><em>lcov</em></a> processes these files into a heap of HTML files using the following command line:</p>\n<div class=\"gatsby-highlight\" data-language=\"none\"><pre class=\"language-none\"><code class=\"language-none\">$ lcov -c -b \"$(base-directory)\" -d \"$(metadata-directory)\" -o coverage.info\n$ genhtml -o cov coverage.info</code></pre></div>\n<p>The <em>$base-directory</em> in this case is used to resolve relative paths as our build system outputs its artifacts in a sibling directory of the source directory. So for example the source files will be called <code class=\"language-text\">../src/xmms/medialib.c</code>, where <code class=\"language-text\">..</code> is relative to <code class=\"language-text\">_build_</code>. The <code class=\"language-text\">$metadata-directory</code> is the directory to recursively scan for <code class=\"language-text\">.gcda</code> files. See the <a href=\"https://web.archive.org/web/20110312104907/http://ltp.sourceforge.net/coverage/lcov/lcov.1.php\" title=\"man page of lcov\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><em>man page</em></a> for further details.</p>\n<p>So we now know that our tests produce the correct result, they don’t leak, and we’ve verified via coverage that our tests cover the complex code paths we want them to. Already this gives us a lot of comfort that what we’re doing is correct, but there’s one more tool we can use to increase that comfort and that is the beautiful free <a href=\"https://web.archive.org/web/20110613100820/http://clang-analyzer.llvm.org:80/\" title=\"Clang Static Analyzer\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><em>static analysis tool from the clang project</em></a>. To perform a static analysis of the XMMS2 source code simply issue the following commands:</p>\n<div class=\"gatsby-highlight\" data-language=\"none\"><pre class=\"language-none\"><code class=\"language-none\">scan-build ./waf configure\nscan-build ./waf build</code></pre></div>\n<p>After a while the analysis is done and you will be presented with a command to run which opens your browser with the static analysis report. This is the latest addition to our tool chain which will help us to increase our code quality even further, so there are still some warnings of different severities left which should be fixed.</p>\n<p>Now on to the future. While working on getting <a href=\"http://xmms2.org/wiki/Collections_2.0\" title=\"Collections 2.0\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><em>Collections 2.0</em></a> into shape I started working on a comfortable way of validating the correctness while getting to know the whole concept and the code behind it so that I could easily modify its structure without breaking things.</p>\n<p>First step was to build the data structures via the C-API like clients would, and some basic validation of the result. This turned out to be pretty verbose as the whole data structures would be written out in code instead of generated from some kind of user interface. The first step was to write a small JSON parser that constructed a <code class=\"language-text\">xmmsv_t</code> which could be used to build the <a href=\"http://xmms2.org/wiki/Collections_2.0#fetch-specification\" title=\"Collections 2.0 Fetch Specification\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><em>fetch specification</em></a>, so that by looking at a test for a second you’d know exactly what the result would be. After this the next obvious step was to construct a <code class=\"language-text\">xmmsv_t</code> from JSON with the expected result. Here a vision of an entirely code-free test suite started to grow, and some lines of code later a <code class=\"language-text\">xmmsv_coll_t</code> could also be constructed from JSON.</p>\n<p>The envisioned test-runner is not committed yet, but what it does is to scan a directory structure like this:</p>\n<div class=\"gatsby-highlight\" data-language=\"none\"><pre class=\"language-none\"><code class=\"language-none\">testcases/test_query_infos_order_by_tracknr/medialib.json\ntestcases/test_query_infos_order_by_tracknr/collection.json\ntestcases/test_query_infos_order_by_tracknr/query.json\ntestcases/test_query_infos_order_by_tracknr/expected.json\ntestcases/test_something_complex/medialib.json\ntestcases/test_something_complex/collection.json\ntestcases/test_something_complex/query.json\ntestcases/test_something_complex/expected.json</code></pre></div>\n<p>And for each directory under <code class=\"language-text\">testcases</code> it performs the same task as the current test framework does, but now in a way that makes it easy for non C-coders to contribute new test cases.</p>\n<p>A bonus here is that it’s easy to re-use this collection of test cases for other types of tests, such as performance tests, which actually already works. When running the suite in performance mode another directory is scanned for media libraries of different sizes (500, 1000, 2000, 4000, 8000, 16000 songs) on which each of the tests are executed, and performance metrics per test is dumped on <code class=\"language-text\">stdout</code>.</p>\n<p>The idea is that these performance tests will emit data in a format that can be used for producing nice graphs based on different metrics. The script that produces the graphs would take as input a number of test-runs, so that you could easily compare multiple versions of the code to check for performance improvements and regressions.</p>\n<p>So that’s it folks, if you have recommendations on further improvements, don’t hesitate to join the IRC channel for a chat, or perhaps drop me a mail.</p>","fields":{"slug":"posts/2011-02-14-software-quality-in-an-open-source-world","readingTime":{"text":"5 min read"}},"frontmatter":{"title":"Software Quality in an Open Source World","date":"14 Feb '11"}},"headerImage":{"childImageSharp":{"fluid":{"tracedSVG":"data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' width='400' height='27'%3e%3cpath d='M2 1L1 13l-1 6c0 4 0 4 3 4 2 0 2 0 1 1H1l-1 1c0 2 3 2 15 2h14v-5c0-5-1-6-3-4v3c0 1-2 2-5 2l-4 1-2 1-2-1c0-2 6-4 9-4 3 1 3-1-1-2-3 0-1-2 4-2 3 0 4-1 4-3l-1-3H16C5 10 5 10 5 3c0-3-2-4-3-2m32 13v13h9c7 0 9 0 9-2 0 0-1-2-3-2-3-1-3-1-2-8V9h-3l-4 1V5c0-5 0-5-3-5h-2l-1 14m20-2v11h4c3 0 4 0 5 2 0 2 1 2 14 2 16 0 15 1 15-11 0-8 1-12 3-12l1 10c0 6 0 9 1 8 1-2 1-2 1 0 1 1 1 2 2 1l2 1 1 2V4c0-3-1-4-6-4-6 0-6 0-5 2 0 4-8 7-20 7h-9V0h-9v12m57-5c-1 8 0 14 4 17v1l-2 1 14 1 14-1h2l10 1c11 0 11 1 11-22V0l-2 3-2 4c1 1 0 1-3 1l-7 1-5-1c-3-3-2-5 1-5l3-1h-3l-3-1-2-1-1 1c1 0-1 3-3 3l-3-2c-3-2-4-2-9-2h-11c-3 0-3 0-3 7m68-4c0 3 0 3 2 1 0-1 2-2 3-1 1 0 1 1-1 3-2 1-2 2-1 2v1l-1 3c0 1-1 2-2 1v6c0 1 1 2 5 2 7 2 8 2 2 2l-6 1h2l3 1c0 1 2 2 10 2 9 0 10 0 10-2 0-1 1-2 3-2h3V0h-33l1 3m36-2c-2 2 0 26 1 26v-1c0-2 1-2 3 0l9 1h8l-2-3-1-2c1-1-6-14-7-13-2 1-5-1-5-5-1-3-1-3-2-1l-1 3V3c0-2-2-4-3-2m99 0c-1 2 3 8 5 9v3l-1-1-2-1 1 2v2c-2 1-2 1-2-1s0-2-1-1h-2l-1 2 1 2 1-1h1l-1 2-1 3-2-3c-2-2-7-2-5 0h2l1 1-3 1c-2 0-2 0-2 2l1 3c0 2 1 2 48 2h48V15c0-10 0-11-2-11-1 0-2 0-2-2 0-3-9-3-11 0v2h-1l-1 1c-1 1-1 0-1-2 1-4-1-4-2 0 0 2-1 2-1 1V2c0-2 0-2-1-1l-2 1c1 4-1 6-4 5-4 0-6-2-3-2 2 0 2 0 1-1-2 0-2-1-1-2l2 1c0 2 1 1 3-1 1-2 0-2-3-2l-7 2c-2 1-2 2-1 2h2l-2 1-2 2 2 1c2-1 4 0 4 2l-5 1-6 1h-1l2-2 1-2-2-4V0h-9c-9 0-10 0-10 2l-1 3V2c0-2-1-2-3-2l-3 1h-2c-2-1-7-1-7 1l1 1v1c0 2-2 0-2-2s-5-3-6-1m-44 7l-1 1c-1-1-1 1-1 3 0 4 0 4-1 1 0-3-1-3-5-4l-6-1c-1 0-1 4 1 10l2 6c1 3 1 3 11 3 7 0 9 0 9-2v-3l-2-2-2-5-3-5c-1-4-2-5-2-2' fill='%23d3d3d3' fill-rule='evenodd'/%3e%3c/svg%3e","aspectRatio":14.867924528301886,"src":"/static/843c5f7defd25c41f8cae57182fd6f1f/1bdc6/wastelands-header.jpg","srcSet":"/static/843c5f7defd25c41f8cae57182fd6f1f/accda/wastelands-header.jpg 200w,\n/static/843c5f7defd25c41f8cae57182fd6f1f/fc61b/wastelands-header.jpg 400w,\n/static/843c5f7defd25c41f8cae57182fd6f1f/1bdc6/wastelands-header.jpg 800w,\n/static/843c5f7defd25c41f8cae57182fd6f1f/34bdc/wastelands-header.jpg 1200w,\n/static/843c5f7defd25c41f8cae57182fd6f1f/bdccb/wastelands-header.jpg 1600w,\n/static/843c5f7defd25c41f8cae57182fd6f1f/0ffcb/wastelands-header.jpg 3940w","sizes":"(max-width: 800px) 100vw, 800px"}}},"indexImage":null},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"posts/2011-02-14-software-quality-in-an-open-source-world","previous":{"fields":{"slug":"posts/2010-07-22-the-garbage-garbage-collector-of-python"},"frontmatter":{"title":"The Garbage Garbage Collector of Python"}},"next":{"fields":{"slug":"posts/2011-08-08-improving-quality-of-life-in-gdb"},"frontmatter":{"title":"Improving quality of life in GDB"}}}}}